---
title: "Lab 2"
output: html_document
editor_options: 
  chunk_output_type: console
---

## Epidemiology data revisited

We start with a recap of the Epidemiology data (cancer rates) from the chapter on count models.

```{r}
#| label: r-ggplot-setup
#| echo: false
# Global plot theming, bw with darker gridlines
# Copied from lecture notes
library(ggplot2)
theme_set(
  theme_bw(base_size = 12) +
  theme(
    panel.grid.major = element_line(colour = "grey85"), # Darker grid lines
    panel.grid.minor = element_line(colour = "grey90") # Darker grid lines
  )
)

# Use global colour palette for discrete colours
options(
  ggplot2.discrete.colour = palette.colors(palette = "R4")
  ) 
update_geom_defaults("point", list(size = 2, color = "#005398"))
```


```{r}
#| label: r-cancer-load-data
cancer <- read.table('https://github.com/UofGAnalyticsData/APM/raw/refs/heads/main/cancer.txt',
                     header=TRUE)
head(cancer)
```

```{r}
#| label: r-cancer-glm-allvars
epid1 <- glm(Y_all ~ pm10 + smoke + ethnic + log.price + easting + northing+offset(log(E_all)), family = poisson, data = cancer)
summary(epid1)
```

:::{.question}

For the epidemiology cancer data. Interpret the `smoke` coefficient output from the `glm()` model, in the same was we just did for `pm10`.

**Specific questions**

(a) Find the rate ratio associated with a one unit increase. Then choose a more sensible size of increase and repeat.

(b) Find the standard deviation of the smoke variable, and use it to find the confidence interval (and point estimate) for the rate ratio associated with a single standard deviation movement in the variable.

:::
<!-- end of Task -->

:::{.content-visible when-profile="answers"}
:::{.answer}

(a) We can either take $\exp(0.00335159)=1.00336$ and interpret it as the rate ratio associated with one unit increase in the percentage of people who smoke or we can choose another percentage, *e.g.* $10\%$.

Using a $10\%$ increase, we interpret $\exp(0.00335159*10)=1.034$ as the rate ratio associated with an increase of 10 units in the percentage of people who smoke.

A common and less arbitrary choice would be to use the standard deviation of the variable in question.

(b) The standard deviation of `smoke` is

```{r}
#| label: r-cancer-sd-smoke
sd(cancer$smoke)
```

which in this case turns out to be quite similar. A point estimate and an approximate confidence interval for the rate ratio associated with one standard deviation increase in the percentage of people who smoke can be obtained as follows:

```{r}
#| label: r-cancer-rate-ratio-smoke
point_est <- exp(0.00335159*sd(cancer$smoke)) # point estimate

lower <- exp((0.00335159-1.96*0.0009462959)*sd(cancer$smoke)) # approx 95% CI lower limit

upper <- exp((0.00335159+1.96*0.0009462959)*sd(cancer$smoke)) # approx 95% CI upper limit

c(lower, point_est, upper)
```

So we see a range from $1.4\%$ and $5.4\%$ with point estimate of $3.3\%$, note that even the lower bound is greater than $1$, so our model is suggesting that a standard deviation increase in `smoke` percentage is associated with an increase in cancer rates (at our 95% level).

:::
:::
<!-- end of Answer -->

## Galapagos data revisited

:::{.question}

(a) Fit a [Poisson regression model]{.term} to the Galapagos data after log-transforming the explanatory variables. 

(b) Does this model fit the data better than the original Poisson model?

(x) For this first model, interpret the $\log(Area)$ coefficient. Comment on your result in comparison to using Area as an offset.

(c) Are all the explanatory variables significant? Investigate a little.

(d) Calculate the dispersion parameter for your chosen Poisson model.

(e) Investigate dropping covariates from the model based on adjusted p-values using the dispersion parameter.

(f) Could we compare these quasi-poisson models with AIC values?


*Hint:*: Log-transforming all the variables before you fit your GLM may require a little care with one of the variables.

:::
<!-- end of Task -->

:::{.content-visible when-profile="answers"}
:::{.answer}

(a) If we $\log$ all variables, there is an issue with the distance to Santa Cruz variable, as it contains a zero. The standard way to approach this is to just add a small constant to avoid a $\-infty$, e.g $\log(x+0.1)$ where $0.1$ is chosen to be small relative to the size of the variable. After inspecting `Scruz` we see that $0.1$ is fine.


```{r}
#| label: r-gala-glm-logs-allvars
library(faraway)
gal4<- glm(Species ~ log(Area)+ log(Elevation) + log(Nearest) + log(Scruz+0.1) + log(Adjacent),family=poisson,data = gala)
summary(gal4)
```

(b) In the [Poisson model]{.term} there is a substantial reduction in [deviance]{.term} when using the log-transformed variables. Suggesting a much better fit.

(x) Our estimated coefficient is $\beta_1=0.348$, let us remind ourselves what are systematic component looked like

$$
\begin{aligned}
\log(\mu_i) = & \beta_0 + \beta_1 \log(\text{Area}_i) + \beta_2 \log(\text{Elevation}_i) + \\
& + \beta_3 \log(\text{Nearest}_i) + \beta_4 \log(\text{Scruz}_i+0.1) + \beta_5 \log(\text{Adjacent}_i)
\end{aligned}
$$

Exponentiating both sides:
$$
\mu_i = e^{\beta_0} \, \text{Area}_i^{\beta_1} \, \text{Elevation}_i^{\beta_2} \times \text{(other terms)}
$$

So the best we seem to be able to say is that our mean $\mu_i$ scales like the $0.348$-th power of the island Area. Notice this is considerable less than 1.

Had we used Area as an offset, this would essentially have been saying that we expect $\beta_1=1$ (i.e. double island area, twice as many species). Our model fit result is suggesting that using an offset for area would have been a bad idea. Intuitively this is reasonable as we're not counting numbers of animals, but different species. Were our dataset one which just counted raw animals then we may indeed have found $\beta_1 \approx 1$ was reasonable.

(c) Also log(`Elevation)` does not appear to be significant. We can drop the term for `Elevation` from the model:

```{r}
#| label: r-gala-glm-logs-reducedvars
gal5 <- glm(Species ~ log(Area) + log(Nearest) + log(Scruz+0.1) + log(Adjacent),family=poisson, data = gala)
summary(gal5)
```

AIC improved and the residual deviance change was marginal. So we are happier with this new model.

(d) Since there are still signs of [overdispersion]{.term}, we will choose to estimate the [dispersion parameter]{.term} and use it in a [quasi-Poisson model]{.term}:

```{r}
#| label: r-gala-glm-logs-quasisummary
#dispersion parameter
dp <- sum(residuals(gal5,type="pearson")^2)/gal5$df.res

summary(gal5, dispersion=dp)

```

(e) Using the adjusted standard errors (under the quasipoisson adjustment) we can now look to drop insignificant covariates.

It looks like more terms can be dropped. When dropping terms, make sure you don't drop more than one at a time.

```{r}
#| label: r-gala-glm-logs-drop1
drop1(gal5, test="F")
```
It looks like distance to Santa Cruz can be dropped.

Repeating the process we see that distance to nearest neighbour can also be dropped and the final model is one with only terms for the logarithm of the area of the island and the logarithm of the area of the adjacent island.


(f) We notice the AIC values are worse for these final models. However, recall that AIC is a likelihood based statistic and the quasi-poisson model is not using a real likelihood. These AICs reported by R will be the AIC under the original Poisson model. Since we don't believe Poisson to be a good model (due to the observed overdispersion) we are not going to use the AIC values.

*This whole approach is a little on heuristic side. In reality it would be good, with enough data, to think about approaches using cross-validation or test-train methodology to validate our model(s).* 

:::
:::
<!-- end of Answer -->

## Epidemiology deeper study

:::{.question}

In the epidemiology case study (start of "Models for count data" section), the [residual deviance]{.term} of the fitted model is quite high compared to the degrees of freedom. So we will investigate overdispersion.

Fit a [quasi-Poisson model]{.term} and a [negative binomial model]{.term} and explore diagnostic plots to check if one of these might be more appropriate.

**Specifically**

(a) After fitting a quasi-poisson, plot predicted counts against standardized Pearson residuals (for original and quadi- models).
(b) Create a scatterplot of $\hat{\mu}_i$ against raw residuals squared ($\left(y_i-\hat{\mu}_i\right)^2)$ to investigate whether the relationship is linear or quadratic.
:::
<!-- end of Task -->


:::{.content-visible when-profile="answers"}
:::{.answer}

(a) Start by fitting a [quasi-Poisson model]{.term} following the analysis steps for the Galapagos data:

```{r}
#| label: r-cancer-quasi-summary-and-phi

epid2 <- glm(Y_all ~ pm10 + smoke + ethnic + log.price + easting + northing+offset(log(E_all)), family=quasipoisson(link = "log"), data = cancer)
summary(epid2)

# Calculate the dispersion parameter:
pearson <- residuals(epid1, type = "pearson")
sum(pearson^2)/epid1$df.residual
```

```{r}
#| label: fig-cancer-poisson-vs-quasi
#| fig-cap: "Plots of predicted counts against Standardised Pearson Residuals, for regular Poisson likelihood and modified Quasi-likelihood."
#| fig-alt: "Around 10 points lie outside (-3,3) in the plot of Standardised Pearson Residuals for the regular likelihood, but for the Quasi-likelihood we now don't see such outliers, the distribution is far more believable Normal(0,1)."
#| echo: false
#| fig-pos: "H"
library(ggplot2)

# Compute predictions and standardized residuals
pred1 <- predict(epid1, type = "response")
resid1 <- rstandard(epid1, type = "pearson")
pred2 <- predict(epid2, type = "response")
resid2 <- rstandard(epid2, type = "pearson")

# Prepare data for plot and order of plots (reg first)
plotdata <- rbind(
  data.frame(pred = pred1, resid = resid1, Model = "Regular likelihood"),
  data.frame(pred = pred2, resid = resid2, Model = "Quasi-likelihood")
)

plotdata$Model <- factor(plotdata$Model, levels = c("Regular likelihood", "Quasi-likelihood"))

ggplot(plotdata, aes(x = pred, y = resid)) +
  geom_point(shape = 1, alpha = 0.7, size = 3) +
  geom_hline(yintercept = c(-3, -2, 0, 2, 3), linetype = "dotted", color = "red") +
  facet_wrap(~Model) +
  xlab("Predicted count") +
  ylab("Standardized Pearson residuals") +
  ylim(-5, 5) + theme(strip.text = element_text(size = 14))


```

We see that for the cancer data, just like for the Galapagos data, all of the [residuals]{.term} are contained within $\pm 3$ in the [quasi-Poisson model]{.term}, while quite a few are outside this range for the original [Poisson model]{.term}.

Next we fit a [negative binomial model]{.term}:

```{r, fig.height=4}
#| label: r-cancer-nb-logs
library(MASS)
epid3 <- glm.nb(Y_all ~ pm10 + smoke + ethnic + log.price + easting + northing + offset(log(E_all)), data = cancer)
summary(epid3)
```

(b) *This is similar to what is seen in lectures with two different examples*

To decide between the [quasi-Poisson]{.term} and the [negative binomial model]{.term}, we plot $(y_i-\hat{\mu}_i)^2$ versus $\hat{\mu}_i$ and compare the linear and quadratic fit to see which one of them fits better.


```{r}
#| label: fig-r-cancer-nb-versus-quasi-plot
#| fig-cap: "Scatterplot of squared raw residuals against predicted counts. Overlaid are lines of best fit, linear and quadratic."
#| fig-alt: "Both linear and quadratic lines of best fit are very similar. Points show a general upward trend, but at best a weak linear correlation. No good reason to prefer the more complex quadratic."
#| echo: false
#| fig-pos: "H"

res.sq <- residuals(epid1, type = "response")^2
set1 <- data.frame(res.sq, mu.hat = epid1$fitted.values)

fit.lin <- lm(formula = res.sq ~ mu.hat, data = set1)
fit.quad <- lm(formula = res.sq ~ mu.hat + I(mu.hat^2), data = set1)

# Choose x-resolution and generate lines
mu.seq <- seq(min(set1$mu.hat), max(set1$mu.hat), length.out = 12)
pred.lin <- predict(fit.lin, newdata = data.frame(mu.hat = mu.seq))
pred.quad <- predict(fit.quad, newdata = data.frame(mu.hat = mu.seq))

pred.df <- data.frame(
  mu.hat = rep(mu.seq, 2),
  res.sq = c(pred.lin, pred.quad),
  model = factor(rep(c("Linear", "Quadratic"), each = length(mu.seq)))
)

ggplot(set1, aes(x = mu.hat, y = res.sq)) +
  geom_point(shape = 1) + 
  geom_line(data = pred.df, aes(x = mu.hat, y = res.sq, color = model, linetype = model)) +
  scale_linetype_manual(values = c("Linear" = "solid", "Quadratic" = "dashed")) +
  scale_color_manual(values = c("Linear" = "blue", "Quadratic" = "red")) +
  xlab("Predicted count") + ylab("Squared Residual") +
  labs(color = NULL, linetype = NULL) +  # remove legend title
  theme(
    legend.position = c(0.05, 0.95),  # top-left inside plot
    legend.justification = c(0, 1),   
    legend.key.width = unit(2, "cm"),
    legend.background = element_rect(  # box around legend
      color = "black",
      linewidth = 0.2
    )
  )
```


The straight line fit (blue line) would indicate that the [quasi-Poisson model]{.term} should be preferred, and the quadratic fit (red line) would suggest using a [negative binomial model]{.term}.

The quadratic coefficient in the above model has a $p$-value of 0.411 -- not significant. We don't have any evidence that the [negative binomial model]{.term} is better and we can probably go with either one. Not a very conclusive investigation!
:::
:::
<!-- end of Answer -->

## Simpson's paradox

Simpson's paradox is a phenomenon in which apparent associations get reversed when we look at aggregates. A very simple example of this is the following:

Suppose that I get better grades than you in easy courses and I also get better grades than you in hard courses, and yet your GPA is higher than mine. How can this be? 

I take lots of hard courses where I get mostly Cs and you get mostly Ds, and you take lots of easy courses where you get mostly Bs and I get mostly As. Even though I do better than you when we control for the difficulty of the course, your overall GPA will be higher.

Here is another example with a contingency table.


### Death penalty in the US


This dataset comes from *Categorical Data Analysis* by Alan Agresti. The $2 \times 2 \times 2$ table shows homicide cases in Florida over the period 1976-77. The defendant's race and victim's race, each having categories white or black, and whether there was a death penalty verdict (yes/no), was recorded. 


+-------------------+---------------+-----+-----+-------------+
| Defendant's Race  | Victim's Race | Yes | No  | Percentage  |
+===================+===============+=====+=====+=============+
|                   | White         | 19  | 132 | 12.6        |
| White             +---------------+-----+-----+-------------+
|                   | Black         | 0   | 9   | 0.0         |
+-------------------+---------------+-----+-----+-------------+
|                   | White         | 11  | 52  | 17.5        |
| Black             +---------------+-----+-----+-------------+
|                   | Black         | 6   | 97  | 5.8         |
+-------------------+---------------+-----+-----+-------------+

: Full original data of death penalty verdicts {#tbl-racedeath-alltable-grid tbl-colwidths="[15,15,15,15,15]" .striped .hover}

The following is the marginal table obtained by summing the cell counts over the levels of victim's race.

| Defendant's Race | Death Penalty: Yes | Death Penalty: No | Total   | Percentage (Yes) |
|:-----------------|:------------------:|:-----------------:|:-------:|:----------------:|
| White            | 19                 | 141               | 160     | 11.9             |
| Black            | 17                 | 149               | 166     | 10.2             |
| Total            | 36                 | 290               | 326     |                  |

: Marginal summaries, ignoring victim's race {#tbl-deathrace-marginal tbl-colwidths="[20,20,20,10,15]" .striped .hover}

About 12\% of white defendants and about 10\% of black defendants received the death penalty. Ignoring the victim's race, the percentage of "yes" death penalty verdicts was lower for blacks than for whites.

However taking the victim's race into account, things look completely different: When the victim was white, the death penalty was imposed about 5 percentage points more often for black defendants than for white defendants. When the victim was black, the death penalty was imposed over 5 percentage points more often for black defendants than for white defendants. Controlling for the victim's race, the percentage of "yes" death penalty verdicts was higher for blacks than for whites.

The phenomenon in which a pair of variables have marginal association of different direction from their partial associations is called *Simpson's paradox*. In the death penalty example, it arises because whites tended to kill whites, and killing a white person was more likely to result in the death penalty.

:::{.question}

Fit a variety of possible loglinear models to the death penalty data and interpret them in terms of the associations between the variables.

*To get you started I recommmend you create the following data frame, then inspect it*

```{r}
#| label: r-deathrace-df-help
#| 
deathpenalty <- data.frame (D=rep(c("white","white","black","black"),2),
                            V=rep(c("white","black"),4),
                            P=c(rep("yes",4),rep("no",4)),
                            freq = c(19,0,11,6,132,9,52,97))
```
*You can now fit models for `freq` in terms of `D`, `V` and `P`.*

:::
<!-- end of Task -->

:::{.content-visible when-profile="answers"}
:::{.answer}


Let $P$ stand for death penalty, $V$ for victim's race and $D$ for defendant's race. Create a data.frame with the data:
```{r}
#| label: r-racedeath-simpsons-table
deathpenalty <- data.frame (D=rep(c("white","white","black","black"),2),
                            V=rep(c("white","black"),4),
                            P=c(rep("yes",4),rep("no",4)),
                            freq = c(19,0,11,6,132,9,52,97))

xtabs(freq ~ D + V+ P, data=deathpenalty)
```

Start from fitting the full independence model:

```{r}
#| label: r-racedeath-glm-additive
glm(freq ~ D + V+ P, family=poisson, data=deathpenalty)
```
and try all models up to this fully saturated model:

```{r}
#| label: r-racedeath-glm-interactions
glm(freq ~ D*V*P, family=poisson, data=deathpenalty)
```

| Terms in model | Deviance  | Degrees of Freedom |
|:---------------|----------:|-------------------:|
| [D,V,P]        | 137.93    | 4                  |
| [D,VP]         | 131.68    | 3                  |
| [V,DP]         | 137.71    | 3                  |
| [P,DV]         | 8.13      | 3                  |
| [DP,VP]        | 131.46    | 2                  |
| [DP,DV]        | 7.91      | 2                  |
| [VP,DV]        | 1.88      | 2                  |
| [DP,VP,DV]     | 0.70      | 1                  |
| [DVP]          | 0.00      | 0                  |

: List of deviances and degrees of freedom for all possible models {#tbl-racedeath-deviances-allmodels .striped .hover}

Notice that any model that does not include the term `D*V` has a large [deviance]{.term}. This suggests an important association between the defendant's race and the victim's race. Other than the [saturated model]{.term}, the two models that appear to fit the data well when we compare the [deviance]{.term} with a chi-squared distribution with the corresponding [degrees of freedom]{.term}, are $[VP,DV]$  and $[DP,VP,DV]$. The simpler model says that the death penalty verdict is independent of the defendant's race, given the victim's race. In the model with all two-way interactions, all pairs of variables are conditionally dependent.
:::
:::
<!-- end of Answer -->

## Zero-inflated models

:::{.question}

Here is a dataset (from [UCLA](https://stats.idre.ucla.edu/stat/data/fish.csv)) which records how many fish visitors to a US National Park caught during their trip.

We will look at a particular set of covariates:

```{r}
#| message: false
library(dplyr)
zinb <- read.csv("fish_catch.csv")
zinb <- zinb %>% 
  select(camper, persons, child, count) %>% 
  tibble()
zinb
```

* `camper` which tells us whether they came in a camper/caravan;
* `persons` the number of people in the group;
* `child` the number of children in the group;
* `count` the number of fish caught.

Some groups went fishing, and others did not, but we don't have this in our data. Thus we have two sources of zeros in `count`.

We will use just `persons` in a logistic model to create structural zeros (they didn't go fishing).

Then to model the number of fish caught we will use `camper` and `child`.

```{r}
library(pscl)
m1 <- zeroinfl(count ~ child + camper | persons, data = zinb)
summary(m1)
```

Look at this output and (with the help of some searching online if you wish) comment on what has been done by the `zeroinfl` function.

You should look to include:

* Why are there two tables?
* What signs are the estimates?
* What do the linear components (and this systematic components) look like for the two parts of the model?

:::
<!-- end of question -->

:::{.content-visible when-profile="answers"}
:::{.answer}

This is a zero-inflated Poisson model (ZIP).

* Count model (Poisson) – predicts the fish count if the observation is not a structural zero.

* Zero-inflation model (Logistic) – predicts the probability of a structural zero (observation must be zero).

| Model                       | Coefficient | Sign | Comment                                                                            |
| --------------------------- | ----------- | ---- | ---------------------------------------------------------------------------------- |
| Count (Poisson, log link)   | child       | -    | More children present means lower predicted fish catch                             |
| Count (Poisson, log link)   | camper      | +    | Camper/caravan present means increased predicted fish catch                        |
| Zero (Binomial, logit link) | persons     | -    | More people in group decreases probability of a structrural zero                   |


**Count model** (Poisson, log link)
$$
\eta_{\text{count}} = 1.598 - 1.043 \cdot \text{child} + 0.834 \cdot \text{camper}
$$

**Zero-inflation model** (Binomial, logit link)
$$
\eta_{\text{zero}} = 1.297 - 0.564 \cdot \text{persons}
$$
These are the linear components. The first is $\log(\mu_i)$ and the latter is $\log\left(\frac{p_i}{1-p_i}\right)$.

:::
:::